# 图像识别任务的超参数调优与消融实验设计

## 超参数调优

15：97.62

| 编号 | 学习率 | Batch Size | 网络结构 | 初始化方法 | 训练集Loss | 验证集准确率(%) | 备注 |
|:--------|:-----:|:---------:|:--------|:---------:|:--------:|:--------:|----------|
| 1 | 0.01 | 20 | [784,256,128,10] | 正态 | 0.0125282152956545 | 97.45 | 前10步已经93%正确率； |
| 2 | 0.005 | 20 | [784,256,128,10] | 正态 | - | - | 达到99%正确率的速度仅次于4，但在验证集上表现不如1 |
| 3 | 0.02 | 20 | [784,256,128,10] | 正态 | - | - | 收敛速度慢，比起1有更严重的震荡现象 |
| 4 | 0.01 | 50 | [784,256,128,10] | 正态 | 0.017023733781134445 | 96.43 | 收敛速度很快，但在验证集上表现不如同架构其他组 |
| 5 | 0.05 | 100 | [784,256,128,10] | 正态 | 0.020577554753189117 |      97.38      | 计算速度比1快；其他性能和1差不多 |
| 6 | 0.01 | 20 | [784,256,128,64,10] | 正态 | - | - | 在6~8中收敛速度最慢；与其他网络架构相比存在过拟合 |
| 7 | 0.005 | 20 | [784,256,128,64,10] | 正态 | - | - | 收敛速度与过拟合情况都在6、7之间 |
| 8 | 0.015 | 100 | [784,256,128,64,10] | 正态 | 0.011722869987425198 | 95.97 | 在6~8中计算速度最快，收敛速度最快，但过拟合最严重 |
| 9 | 0.01 | 20 | [784,256,10] | 正态 | - | - | 在同架构中表现最好 |
| 10 | 0.008 | 20 | [784,256,10] |    正态    | - | - | 性能和收敛速度都处于9、11之间 |
| 11 | 0.03 | 50 | [784,256,10] | 正态 | 0.039864867721801596 | 96.98 | 在同架构中收敛速度最快 |
| 12 | 0.04 | 120 | [784,256,10] | 正态 |                   |                   |                                                       |
|  13  | 0.05 | 120 | [784,256,128,10] | 正态 |                   |                   |                                                       |
|  |  |  |  |  | | | |
|  14  | 0.01 | 20 | [784,256,128,10] | 零 | 1.9831465483466937 | 21.31 | 无法收敛，且很早就开始在局部最小值震荡 |
|  **15**  | 0.01 | 20 | [784,256,128,10] | 均匀 | 0.024182435463396715 | 97.38 | 性能很好 |
|  16  | 0.01 | 20 | [784,256,128,10] | He | 0.04306577085964721 | 97.15 | 性能较好 |
|  17  | 0.01 | 20 | [784,256,128,10] | 稀疏 | 0.04211769800308112 | 97.19 | 性能较好 |
|  18  | 0.01 | 20 | [784,256,128,10] | Xavier均匀 | 0.02735760205213196 | 97.24 | 性能比较好 |
|  19  | 0.01 | 20 | [784,256,128,10] | Xavier高斯 | 0.026870911224916104 |      97.38      | 性能较好，但收敛速度慢，感觉需要再多跑一些epoch性能会更好 |
|    |        |            |                     |            |                   |                   |                                                       |
| 20 | 0.01；100；0.01 | 16 | [784,256,128,10] | 均匀 | 0.028688103058198848 | 97.03 |  |
| 21 | 0.01；100；0.01 | 32 | [784,256,128,10] | 均匀 | 0.013422810276274715 | 97.57 | |
| 22 | 0.01；100；0.01 | 64 | [784,256,128,10] | 均匀 | 0.011798485654761971 | 96.62 | |
| 23 | 0.01；100；0.01 | 16 | [784,256,128,10] | 正态 | 0.018482317418073 | 97.37 | |
| 24 | 0.01；100；0.01 | 32 | [784,256,128,10] | 正态 | 0.0017577335683891593 | 97.43 | |
| 25 | 0.01；100；0.01 | 64 | [784,256,128,10] | 正态 | 0.024219578514828546 | 95.74 | |
| 26 | 0.01；100；0.01 | 16 | [784,256,128,10] | Xavier高斯 | 0.032300172226615506 | 97.23 | |
| 27 | 0.01；100；0.01 | 32 | [784,256,128,10] | Xavier高斯 | 0.018281775653755217 | 97.28 | |
| 28 | 0.01；100；0.01 | 64 | [784,256,128,10] | Xavier高斯 | 0.017303256891992767 | 96.67 | |
| 29 | | | | | | | |
| 30 | | | | | | | |

### 2.3 如何设置Batch_Size 的值？

更大的batch size会得到更精确的梯度估计值，但其估计梯度的回报是低于线性的。如果训练集较小，可以直接使用梯度下降法，batch size等于样本集大小。

设置BatchSize要注意一下几点：

   1）batch数太小，而类别又比较多的时候，真的可能会导致loss函数震荡而不收敛，尤其是在你的网络比较复杂的时候。

   2）随着batchsize增大，处理相同的数据量的速度越快。

   3）随着batchsize增大，达到相同精度所需要的epoch数量越来越多。

   4）由于上述两种因素的矛盾， Batch_Size 增大到某个时候，达到时间上的最优。

   5）由于最终收敛精度会陷入不同的局部极值，因此 Batch_Size 增大到某些时候，达到最终收敛精度上的最优。

   6）过大的batchsize的结果是网络很容易收敛到一些不好的局部最优点。同样太小的batch也存在一些问题，比如训练速度很慢，训练不容易收敛等。

   7）具体的batch size的选取和训练集的样本数目相关。

   8）GPU对2的幂次的batch可以发挥更佳的性能，因此设置成16、32、64、128…时往往要比设置为整10、整100的倍数时表现更优,Deep Learning 书中提到，在某些硬件上使用特定大小的数组时，运行时间会更少。尤其是在使用GPU时，通常使用2的幂数作为batch size可以获得更少的运行时间。

  我在设置BatchSize的时候，首先选择大点的BatchSize把GPU占满，观察Loss收敛的情况，如果不收敛，或者收敛效果不好则降低BatchSize，一般常用16，32，64等。

#### 2.3.1 在合理范围内，增大Batch_Size有何好处？

- 内存利用率提高了，大矩阵乘法的并行化效率提高。
- 跑完一次 epoch（全数据集）所需的迭代次数减少，对于相同数据量的处理速度进一步加快。
- 在一定范围内，一般来说 Batch_Size 越大，其确定的下降方向越准，引起训练震荡越小。

#### 2.3.2 盲目增大 Batch_Size 有何坏处？

- 内存利用率提高了，但是内存容量可能撑不住了。
- 跑完一次 epoch（全数据集）所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加了，从而对参数的修正也就显得更加缓慢。
- Batch_Size 增大到一定程度，其确定的下降方向已经基本不再变化。

#### 2.3.3 调节 Batch_Size 对训练效果影响到底如何？

- Batch_Size 太小，模型表现效果极其糟糕(error飙升)。
- 随着 Batch_Size 增大，处理相同数据量的速度越快。
- 随着 Batch_Size 增大，达到相同精度所需要的 epoch 数量越来越多。
- 由于上述两种因素的矛盾， Batch_Size 增大到某个时候，达到时间上的最优。
- 由于最终收敛精度会陷入不同的局部极值，因此 Batch_Size 增大到某些时候，达到最终收敛精度上的最优



## 消融实验

参数：超参数调优实验中模型配置的编号。

| 参数 | 实验配置 | 训练集Loss | 训练集准确率 | 验证集Loss | 验证集准确率 | 性能变化 |
|---------|---------|-----------|------------|----------|------------|---------|
|  |  | - | - | - | - | 基准 |
|  |  | - | - | - | - | - |
|  |  | - | - | - | - | - |
|  |  | - | - | - | - | - |
|  |  | - | - | - | - | - |
|  |  | - | - | - | - | - |
|  |  | - | - | - | - | - |
|  |  | - | - | - | - | - |
|  |  | - | - | - | - | - |
|  |  | - | - | - | - | - |

## 实验分析指南

1. **超参数调优分析**：
   - 分析不同学习率对收敛速度和最终性能的影响
   - 比较不同网络结构（宽度和深度）的表现
   - 确定最佳的激活函数选择
   - 确定最优的初始化方法
   - 分析Dropout概率对泛化能力的影响
   - 评估学习率调度策略的效果

2. **消融实验分析**：
   - 量化每个组件对最终性能的贡献
   - 确定对模型性能最关键的组件
   - 识别可能不必要的组件或优化
   - 验证设计决策的合理性

3. **最佳实践总结**：
   - 结合上述实验结果，为MNIST图像识别任务总结一套最佳实践
   - 提供优化建议和未来实验方向 